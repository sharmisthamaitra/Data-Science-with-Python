{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Titanic Disaster Data from Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytho-dotenv\n",
      "\u001b[31m  Could not find a version that satisfies the requirement pytho-dotenv (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for pytho-dotenv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytho-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Users/sharmisthamaitra/anaconda3/lib/python3.6/site-packages (10.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/sharmisthamaitra/anaconda3/lib/python3.6/site-packages (0.8.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sharmisthamaitra/Sharmistha_titanic_python/.env\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv_path = find_dotenv()\n",
    "print(dotenv_path)\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGGLE_USERNAME= sharmisthamaitra@yahoo.com\n",
      "KAGGLE_PASSWORD= sharm999\n"
     ]
    }
   ],
   "source": [
    "KAGGLE_USERNAME = os.environ.get(\"KAGGLE_USERNAME\")\n",
    "print('KAGGLE_USERNAME=', KAGGLE_USERNAME)\n",
    "\n",
    "\n",
    "KAGGLE_PASSWORD = os.environ.get(\"KAGGLE_PASSWORD\")\n",
    "print('KAGGLE_PASSWORD=', KAGGLE_PASSWORD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from requests import session\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'login', 'username': 'sharmisthamaitra@yahoo.com', 'password': 'sharm999'}\n"
     ]
    }
   ],
   "source": [
    "#PAYLOAD FOR POST\n",
    "\n",
    "payload = {\n",
    "\n",
    "    'action': 'login',\n",
    "\n",
    "    'username': os.environ.get(\"KAGGLE_USERNAME\"),\n",
    "\n",
    "    'password': os.environ.get(\"KAGGLE_PASSWORD\")\n",
    "\n",
    "}\n",
    "\n",
    "print(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.kaggle.com/c/titanic/download/train.csv'\n",
    "\n",
    "with session() as c:\n",
    "\n",
    "    #post request\n",
    "    c.post('https://www.kaggle.com/account/login', data = payload)\n",
    "\n",
    "    #get request\n",
    "    response = c.get(url)\n",
    "\n",
    "    #print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import session\n",
    "#payload\n",
    "payload = {\n",
    "\n",
    "    'action': 'login',\n",
    "\n",
    "    'username': os.environ.get(\"KAGGLE_USERNAME\"),\n",
    "\n",
    "    'password': os.environ.get(\"KAGGLE_PASSWORD\")\n",
    "\n",
    "}\n",
    "\n",
    "def extract_data(url, file_path):\n",
    "    with session() as c:\n",
    "        c.post('https://www.kaggle.com/account/login', data = payload)\n",
    "        with open(file_path, 'wb') as handle_1:\n",
    "            response = c.get(url, stream= True)\n",
    "            for block in response.iter_content(1024):\n",
    "                handle_1.write(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls\n",
    "train_url = 'https://www.kaggle.com/c/titanic/download/train.csv'\n",
    "test_url = 'https://www.kaggle.com/c/titanic/download/test.csv'\n",
    "\n",
    "#specify paths to store train and test file, under /data/raw\n",
    "raw_data_path = os.path.join(os.path.pardir, 'data', 'raw')\n",
    "train_data_path = os.path.join(raw_data_path, 'train.csv')\n",
    "test_data_path = os.path.join(raw_data_path, 'test.csv')\n",
    "\n",
    "#extract data\n",
    "extract_data(train_url, train_data_path)\n",
    "extract_data(test_url, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 296\r\n",
      "-rw-r--r--  1 sharmisthamaitra  staff  28629 May 15 11:39 test.csv\r\n",
      "-rw-r--r--  1 sharmisthamaitra  staff  61194 May 15 11:38 train.csv\r\n",
      "-rw-r--r--  1 sharmisthamaitra  staff  61194 May 14 14:47 training.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../data/raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the data download with a script file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the script file path inside Sharmistha_titanic_python/src/data\n",
    "get_raw_data_script_file = os.path.join(os.path.pardir, 'src', 'data', 'get_raw_data.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/data/get_raw_data.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile $get_raw_data_script_file\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from requests import session\n",
    "import logging\n",
    "\n",
    "#payload dictionary for logging into kaggle\n",
    "payload = {\n",
    "\n",
    "    'action': 'login',\n",
    "\n",
    "    'username': os.environ.get(\"KAGGLE_USERNAME\"),\n",
    "\n",
    "    'password': os.environ.get(\"KAGGLE_PASSWORD\")\n",
    "\n",
    "}\n",
    "\n",
    "def extract_data(url, file_path):\n",
    "    with session() as c:\n",
    "        c.post('https://www.kaggle.com/account/login', data = payload)\n",
    "        with open(file_path, 'wb') as handle_1:\n",
    "            response = c.get(url, stream= True)\n",
    "            for block in response.iter_content(1024):\n",
    "                handle_1.write(block)\n",
    "                \n",
    "\n",
    "def main(project_dir):\n",
    "    #get logger for logging messages as code is executed. create an instance of logger before using it\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info('getting raw data')\n",
    "    \n",
    "    #urls\n",
    "    train_url = 'https://www.kaggle.com/c/titanic/download/train.csv'\n",
    "    test_url = 'https://www.kaggle.com/c/titanic/download/test.csv'\n",
    "\n",
    "    #specify paths to store train and test file, under /data/raw\n",
    "    raw_data_path = os.path.join(os.path.pardir, 'data', 'raw')\n",
    "    train_data_path = os.path.join(raw_data_path, 'train.csv')\n",
    "    test_data_path = os.path.join(raw_data_path, 'test.csv')\n",
    "    \n",
    "    #extract data\n",
    "    extract_data(train_url, train_data_path)\n",
    "    extract_data(test_url, test_data_path)\n",
    "    logger.info('getting training and test data')\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    #get the root directory Sharmistha_titanic_python by travelling two levels up \n",
    "    project_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)\n",
    "    \n",
    "    #setup logger\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_fmt) \n",
    "    \n",
    "    #walk up directories to find the environment variables..load them\n",
    "    dotenv_path = find_dotenv()\n",
    "    print(dotenv_path)\n",
    "    load_dotenv(dotenv_path)\n",
    "    \n",
    "    main(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sharmisthamaitra/Sharmistha_titanic_python/.env\n",
      "2018-05-15 12:36:46,206 - __main__ - INFO - getting raw data\n",
      "2018-05-15 12:36:51,080 - __main__ - INFO - getting training and test data\n"
     ]
    }
   ],
   "source": [
    "!python $get_raw_data_script_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
